{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "8c1e8cdc-8ad4-4a41-8688-a64f6436e097"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from io import BytesIO\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "3d9a8fc2-584f-4cdd-89f1-fab7e573f9b1"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '..'\n",
    "img_dirs = (os.path.join(data_path, 'VG_100K'),\n",
    "            os.path.join(data_path, 'VG_100K_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "2e5ffe06-1fff-4173-bfbc-337e61a16d67"
    }
   },
   "outputs": [],
   "source": [
    "image_data_path = os.path.join(data_path, 'image_data.json')\n",
    "objects_path = os.path.join(data_path, 'objects.json')\n",
    "attributes_path = os.path.join(data_path, 'attributes.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "37b5e7c6-41a6-4f22-a0a5-f03d4363df25"
    }
   },
   "outputs": [],
   "source": [
    "with open(objects_path, 'r') as objects_file:\n",
    "    objects_info_list = json.loads(objects_file.read())\n",
    "objects_info = {obj['image_id']: obj\n",
    "                for obj in objects_info_list}\n",
    "\n",
    "with open(attributes_path, 'r') as attributes_file:\n",
    "    attributes_info_list = json.loads(attributes_file.read())\n",
    "attributes_info = {attr['image_id']: attr\n",
    "                   for attr in attributes_info_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "afab4f13-b746-49d0-8777-918777cbe724"
    }
   },
   "outputs": [],
   "source": [
    "objects_counter = Counter()\n",
    "for objects_info_image in objects_info.values():\n",
    "    for object_ in objects_info_image['objects']:\n",
    "        for name in object_['names']:\n",
    "            objects_counter[name] += 1\n",
    "sorted_obj_items = sorted(objects_counter.items(), key=lambda u: (-u[1], u[0]))\n",
    "vocabulary_objects = [item[0] for item in sorted_obj_items]\n",
    "obj_to_ix = {name: ix for ix, name in enumerate(vocabulary_objects)}\n",
    "        \n",
    "attributes_counter = Counter()\n",
    "vocabulary_attributes = set()\n",
    "for attributes_info_image in attributes_info.values():\n",
    "    for attributes_info_object in attributes_info_image['attributes']:\n",
    "        for attribute in attributes_info_object.get('attributes', []):\n",
    "            attributes_counter[attribute] += 1\n",
    "sorted_attr_items = sorted(attributes_counter.items(), key=lambda u: (-u[1], u[0]))\n",
    "vocabulary_attributes = [item[0] for item in sorted_attr_items]\n",
    "att_to_ix = {name: ix for ix, name in enumerate(vocabulary_attributes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = {\n",
    "    'vocabulary_objects': vocabulary_objects,\n",
    "    'obj_to_ix': obj_to_ix,\n",
    "    'vocabulary_attributes': vocabulary_attributes,\n",
    "    'att_to_ix': att_to_ix\n",
    "}\n",
    "vocabulary_path = os.path.join(data_path, 'vocabulary.pkl')\n",
    "with open(vocabulary_path, 'wb') as vocabulary_file:\n",
    "    pickle.dump(vocabulary, vocabulary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "e20b6f85-cef8-4e4a-9c5c-d958e7f62af3"
    }
   },
   "outputs": [],
   "source": [
    "def get_img(img_id, url):\n",
    "    if url is not None:\n",
    "        url_split = url.split('/')\n",
    "        img_name = url_split[-1]\n",
    "    else:\n",
    "        img_name = '{}.jpg'.format(img_id)\n",
    "    for dir_path in img_dirs:\n",
    "        image_path = os.path.join(dir_path, img_name)\n",
    "        if os.path.isfile(image_path):\n",
    "            return Image.open(image_path)\n",
    "    if url is not None:\n",
    "        r = requests.get(url)\n",
    "        r.raise_for_status()\n",
    "        image_path = os.path.join(dir_path, url_split[-2], img_name)\n",
    "        with open(image_path, 'wb') as image_file:\n",
    "            image_file.write(r.content)\n",
    "        return Image.open(BytesIO(r.content))\n",
    "    raise requests.exceptions.HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "7ebbcc2c-785d-4431-bd6c-b7f91c78348a"
    }
   },
   "outputs": [],
   "source": [
    "class WrongModeException(Exception):\n",
    "    pass\n",
    "\n",
    "def preprocess_image(objects_info_image, attributes_info_image, display_images=False):    \n",
    "    img = get_img(img_id=objects_info_image['image_id'], url=objects_info_image.get('image_url', None))\n",
    "    \n",
    "    if img.mode != 'RGB':\n",
    "        raise WrongModeException\n",
    "    \n",
    "    if display_images:\n",
    "        display(img)\n",
    "        print('Original image\\n')\n",
    "\n",
    "    objects = objects_info_image['objects']\n",
    "    N = len(objects)\n",
    "\n",
    "    attributes = attributes_info_image['attributes']\n",
    "    attributes_dict = {object_['object_id']: object_.get('attributes', [])\n",
    "                       for object_ in attributes}\n",
    "    \n",
    "    img_ids = np.ones(N, dtype=np.int) * objects_info_image['image_id']\n",
    "    object_squares = np.empty((N, 3, 224, 224), dtype=np.uint8)\n",
    "    original_sizes = np.empty(N, dtype=np.int)\n",
    "    object_names = np.empty(N, dtype=np.int)\n",
    "    attributes_names = []\n",
    "\n",
    "    for i, (object_, attrs) in enumerate(zip(objects, attributes)):\n",
    "        attrs = attributes_dict[object_['object_id']]\n",
    "        attributes_names.append([att_to_ix[attr] for attr in attrs])\n",
    "        original_sizes[i] = object_['w'] * object_['h']\n",
    "        object_names[i] = obj_to_ix[object_['names'][0]]\n",
    "        \n",
    "        # Image processing\n",
    "        cropped = img.crop((object_['x'],\n",
    "                            object_['y'],\n",
    "                            object_['x'] + object_['w'],\n",
    "                            object_['y'] + object_['h']))\n",
    "        resized = cropped.resize((224, 224))\n",
    "\n",
    "        if display_images:\n",
    "            display(resized)\n",
    "            print(' - '.join(object_['names']))\n",
    "            print()\n",
    "\n",
    "        object_squares[i] = np.rollaxis(np.asarray(resized), axis=2, start=0)\n",
    "\n",
    "    return object_squares, img_ids, original_sizes, object_names, attributes_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "an = preprocess_image(objects_info[2], attributes_info[2])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_label_vector_attr(an, max_num_attribues):\n",
    "    indices = torch.LongTensor([[i, v]\n",
    "                                for i, attr_row in enumerate(an)\n",
    "                                for v in attr_row\n",
    "                                if v < max_num_attribues])\n",
    "    values = torch.ones(len(indices))\n",
    "    return torch.sparse.FloatTensor(indices.t(),\n",
    "                                    values,\n",
    "                                    torch.Size((len(an), max_num_attribues)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "8987f1c9-02c9-4a4d-a7fc-2b28181ad1ad"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preprocess_image(objects_info[2], attributes_info[2], display_images=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c87291a9-be9a-4b6b-9714-22c97164c6dd"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_images(image_ids, save_path):\n",
    "    failed = []\n",
    "    wrong_mode = []\n",
    "    \n",
    "    object_squares = []\n",
    "    img_ids = []\n",
    "    original_sizes = []\n",
    "    object_names = []\n",
    "    attributes_names = []\n",
    "    \n",
    "    for image_id in image_ids:\n",
    "        try:\n",
    "            osq, ii, os, on, an = preprocess_image(objects_info[image_id], attributes_info[image_id])\n",
    "        except requests.exceptions.HTTPError:\n",
    "            failed.append(str(image_id))\n",
    "            continue\n",
    "        except WrongModeException:\n",
    "            wrong_mode.append(str(image_id))\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(image_id)\n",
    "            raise e\n",
    "            \n",
    "        object_squares.append(osq)\n",
    "        img_ids.append(ii)\n",
    "        original_sizes.append(os)\n",
    "        object_names.append(on)\n",
    "        attributes_names += an\n",
    "        \n",
    "    if failed:\n",
    "        print('Failed to load image(s) {}'.format(', '.join(failed)))\n",
    "        \n",
    "    if wrong_mode:\n",
    "        print('Wrong mode for image(s) {}'.format(', '.join(wrong_mode)))\n",
    "        \n",
    "    result = {\n",
    "        'object_squares': np.concatenate(object_squares),\n",
    "        'img_ids': np.concatenate(img_ids),\n",
    "        'original_sizes': np.concatenate(original_sizes),\n",
    "        'object_names': np.concatenate(object_names),\n",
    "        'attributes_names': np.asarray(attributes_names)\n",
    "    }\n",
    "\n",
    "    if save_path is not None:\n",
    "        np.savez_compressed(save_path, **result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "c2b28f41-bb93-400d-8884-9e5557c6b3b6"
    }
   },
   "outputs": [],
   "source": [
    "%store -r image_ids_list\n",
    "image_ids_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "1e97cac4-ae60-44a9-9fda-87ae0b8d0a26"
    }
   },
   "outputs": [],
   "source": [
    "save_dir = os.path.join('./bounding_boxes')\n",
    "interval = 1000\n",
    "for k in range(0, len(image_ids_list), interval):\n",
    "    slice_ = image_ids_list[k:k+interval]\n",
    "    file_name = 'vg_bb_{:07}-{:07}.npz'.format(slice_[0], slice_[-1])\n",
    "    save_path = os.path.join(save_dir,file_name)\n",
    "    if os.path.exists(save_path):\n",
    "        print('{}: {} already exists, skipping...'.format(k, file_name))\n",
    "    else:\n",
    "        print('{}: Generating {}'.format(k, file_name))\n",
    "        preprocess_images(slice_, save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
