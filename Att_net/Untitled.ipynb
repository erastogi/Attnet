{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "import data_loader as name\n",
    "import torch.nn as nn\n",
    "# name.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"blah\"\n",
    "batch_size = 64\n",
    "num_batches = 517\n",
    "count = 0\n",
    "val_id = np.load('val.npy')\n",
    "test_id = np.load('test.npy')\n",
    "\n",
    "val_data = defaultdict(list)\n",
    "train_batch = defaultdict(list)\n",
    "test_data = defaultdict(list)\n",
    "print \"start fetching data\"\n",
    "\n",
    "print num_batches   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in range(num_batches) : \n",
    "    print \"Entered loop..\"\n",
    "    ft , obj , att , vids = name.load_batch(b)\n",
    "    print \" batch loaded \"\n",
    "    vids = np.array(vids)\n",
    "    #get indexes of common test data\n",
    "    ind = np.nonzero(np.in1d(vids, val_id))[0]  \n",
    "    vids = np.delete(vids, ind)\n",
    "    print \" train data ---\" , len(val_data)\n",
    "    \n",
    "    test_data['features'].append(ft[ind,:]) \n",
    "    for i in ind :   \n",
    "        #get index of ones\n",
    "        if np.any(obj[i,:]==1) :\n",
    "            obj_l = np.where(obj[i,:]==1)\n",
    "        if np.any(att[i,:]==1) :   \n",
    "            att_l = np.where(att[i,:]==1)           \n",
    "           \n",
    "      \n",
    "        test_data['object'].append(obj_l)    \n",
    "        test_data['atts'].append(att[i,:])\n",
    "        \n",
    "    #get indexes of common valid data\n",
    "    ind = np.nonzero(np.in1d(vids, val_id))[0]\n",
    "    vids = np.delete(vids, ind)\n",
    "    print \" valid data ---\" , len(val_data)\n",
    "    \n",
    "    val_data['features'].extend(ft[ind,:]) \n",
    "    \n",
    "    for i in ind :   \n",
    "        #get index of ones\n",
    "        if np.any(obj[i,:]==1) :\n",
    "            obj_l = np.where(obj[i,:]==1)\n",
    "        if np.any(att[i,:]==1) :   \n",
    "            att_l = np.where(att[i,:]==1)           \n",
    "        vids = np.delete(vids, ind)    \n",
    "           \n",
    "        val_data['object'].append(obj_l)    \n",
    "        val_data['atts'].append(att[i,:])\n",
    "        \n",
    "    #get  indexes of train data\n",
    "    for i in vids :\n",
    "        if np.any(obj[i,:]==1) :\n",
    "            obj_l = np.where(obj[i,:]==1)\n",
    "        if np.any(att[i,:]==1) :   \n",
    "            att_l = np.where(att[i,:]==1)           \n",
    "        vids = np.delete(vids, ind)    \n",
    "        train_batch['features'].append(ft[i,:])    \n",
    "        train_batch['object'].append(obj_l)    \n",
    "        train_batch['atts'].append(att[i,:])\n",
    "        if len(train_batch) == batch_size :\n",
    "             #save_this_batch\n",
    "             np.save('train_batch' + str(count) + '.npy', train_batch)\n",
    "             print \" train file saved \"\n",
    "             train_batch = defaultdict(list)\n",
    "             count = count + 1\n",
    "             \n",
    "#save test and val array\n",
    "np.save('val_data_att.npy', val_data)\n",
    "np.save('test_data_att.npy' , test_data)             \n",
    "#loading file\n",
    "#np.load('my_file.npy').item()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = '/home/ubuntu/preprocessing/attrnet_data'\n",
    "features = np.load(os.path.join(load_path, 'features.npy'))\n",
    "attrs = np.load(os.path.join(load_path, 'attrs.npy'))\n",
    "objs = np.load(os.path.join(load_path, 'objs.npy'))\n",
    "img_ids = np.load(os.path.join(load_path, 'img_ids.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p27)",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
